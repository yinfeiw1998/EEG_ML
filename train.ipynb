{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the file that contains feature data and read it\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "dataX1 = []\n",
    "dataX2 = []\n",
    "dataX3 = []\n",
    "dataX4 = []\n",
    "dataX5 = []\n",
    "dataX6 = []\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "file_name1 = \"startFrom5Minutes_noOverlap_720.txt\"\n",
    "file_name2 = \"features_startFrom_3minutes(without ica)\"\n",
    "f = open(file_name1, \"r\")\n",
    "#The 0-3000 belongs to 101\n",
    "#The 3000-6000 belongs to 202\n",
    "count = 1\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    count += 1\n",
    "    c = 1\n",
    "    if not line:\n",
    "        break\n",
    "    if(line == \"\\n\" or line == \"\"):\n",
    "        #print(\"found\")\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            raw_data = [i.strip().split() for i in line.strip().split('|')]\n",
    "#             dataX1.append([float(i[0]) for i in raw_data[1:]])\n",
    "#             dataX2.append([float(i[1]) for i in raw_data[1:]])\n",
    "#             dataX3.append([float(i[2]) for i in raw_data[1:]])\n",
    "#             dataX4.append([float(i[3]) for i in raw_data[1:]])\n",
    "#             dataX5.append([float(i[4]) for i in raw_data[1:]])\n",
    "#             dataX6.append([float(i[5]) for i in raw_data[1:]])\n",
    "            temp = []\n",
    "            for i in raw_data[1:]:\n",
    "                for j in i:\n",
    "#                     print(c)\n",
    "#                     if np.isnan(float(j)):\n",
    "#                         temp.append(0)\n",
    "#                         print(int(raw_data[0][0]))\n",
    "#                     else:\n",
    "                    temp.append(float(j))\n",
    "#                 if i!= []:\n",
    "#                     temp.append(float(i[0]))\n",
    "            if temp!=[] and int(raw_data[0][0])!=603:\n",
    "                dataX.append(temp)\n",
    "                dataY.append(int(raw_data[0][0]))\n",
    "\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "    \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print()\n",
    "np.any(np.isnan(dataX))\n",
    "# np.all(np.isnan(dataX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10192 10192 2548 2548\n",
      "102\n",
      "[1.9576639245144398e-05, 2.3761269696299112e-05, 2.0464665398850832e-05, 1.5414662863904488e-05, 1.7284238139996325e-05, 1.5787872923811753e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 45.0, 19.0, 16.0, 19.0, 11.0, 2.454694008549674e-10, 4.1911786177563963e-10, 3.352739474529881e-10, 2.3742135793255765e-10, 1.8827402683533992e-10, 2.0059937218755293e-10, 2.0065534829878726, 1.1842032392904105, 2.086903211559474, 1.8594983396834104, 1.6174970823431416, 1.8873813881184045, 0.9111586098923545, 0.6593341940157309, 0.8299346315408495, 0.8921761453112051, 0.8525041981072466, 0.9869302275073955, 0.02, 0.121, 0.045, 0.035, 0.051, 0.021, 2.0509772946438359e-10, 3.045854488990296e-10, 2.7978277839668395e-10, 1.9713934908792305e-10, 1.5384984210129606e-10, 1.6204333996323335e-10, 0.6239137736957674, 0.40440260625389296, 0.5466859236513109, 0.46903093045380334, 0.4771848866867855, 0.5201895587814348, 0.09420568267909563, 0.1247943658732043, 0.07634102788470484, 0.1834906816923024, 0.20700550353796465, 0.12639162272880336, 0.04718264692288637, 0.05222357827565515, 0.04433327264538, 0.08299558871838006, 0.049814642504693404, 0.06100471058336055, 0.008342210305623743, 0.016065941922165507, 0.008436108192984857, 0.027250486887821092, 0.0161065978126681, 0.013478114958961307, 1.8238359746343414e-11, 5.199011858476491e-11, 2.734162649393064e-11, 4.687140077283625e-11, 2.1649124105612756e-11, 2.3417831885931006e-11, 0.1768067467528465, 0.30763770795948886, 0.19028841521502224, 0.32833656955295804, 0.3233305912242686, 0.22093564300323973, -1.6807803428088142, -1.5300822730313994, -1.6863474441408721, -1.3038409575879948, -1.5542131968446722, -1.49756411263961, 7.0, 24.0, 12.0, 477.0, 5.0, 16.0, 997.0, 998.0, 998.0, 997.0, 997.0, 998.0] 244\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataX, dataY, test_size=0.20, random_state=42)\n",
    "print(len(X_train), len(Y_train), len(X_test), len(Y_test))\n",
    "print(len(X_train[0]))\n",
    "print(X_train[0], Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=7, n_neighbors=10,\n",
      "                     weights='distance')\n",
      "0.4803767660910518\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsClassifier' object has no attribute 'ranking_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5bbf52292490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'ranking_'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "\n",
    "#initialize classifier \n",
    "#for 10 people\n",
    "#nneighbor is 7, weight is distance and score is 76.32\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=10,weights = 'distance', algorithm = 'kd_tree', leaf_size = 7)\n",
    "print(1)\n",
    "# # score: 84.08\n",
    "clf_SVM = make_pipeline(StandardScaler(), SVC(gamma='scale', kernel='rbf'))\n",
    "print(2)\n",
    "# # best score: 78.63\n",
    "clf_DT = DecisionTreeClassifier(random_state=1,criterion='entropy', splitter='best', max_depth=10,max_features=None, max_leaf_nodes=340)\n",
    "print(3)\n",
    "# # best score: 92.33\n",
    "clf_RF = RandomForestClassifier(max_depth=22, random_state=1, n_estimators = 285)\n",
    "print(4)\n",
    "# # best score is: 75.2\n",
    "clf_NN = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(200,75), random_state=1, activation='logistic')\n",
    "print(5)\n",
    "# # score: 65\n",
    "clf_AB = AdaBoostClassifier(n_estimators=100, random_state=0, learning_rate=1, algorithm='SAMME')\n",
    "print(6)\n",
    "# # clf_AB.fit(X_train, Y_train)\n",
    "# # print(clf_AB.score(X_test, Y_test))\n",
    "# #score: 49\n",
    "clf_gnb = GaussianNB()\n",
    "print(7)\n",
    "# # clf_gnb.fit(X_train, Y_train)\n",
    "# # print(clf_gnb.score(X_test, Y_test))\n",
    "# # clf_QDA = QDA()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[ ('SVM', clf_SVM), ('RandomForest', clf_RF)], \n",
    "                                    voting='hard')\n",
    "clf_RF = RandomForestClassifier(max_depth=22, random_state=1, n_estimators = 285)\n",
    "print(8)\n",
    "# eclf.fit(X_train, Y_train)\n",
    "# print(eclf.score(X_test, Y_test))\n",
    "#100 110\n",
    "# for j in range(20,40):\n",
    "#     for i in range(80, 300, 10):\n",
    "#         print(j, i)\n",
    "#         clf_RF = RandomForestClassifier(max_depth=j, random_state=1, n_estimators = i)\n",
    "#         clf_RF.fit(X_train, Y_train)\n",
    "#         print(clf_RF.score(X_test, Y_test))\n",
    "\n",
    "clf_ensem = [clf_KNN, clf_SVM, clf_DT, clf_RF, clf_NN, clf_AB, clf_gnb, eclf]\n",
    "for clf in clf_ensem:\n",
    "    print(clf)\n",
    "#     for i in range(20,100, 20):\n",
    "#         print(i)\n",
    "#     array.reshape(-1, 1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(clf.score(X_test, Y_test))\n",
    "    print(clf.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataX[0])\n",
    "len(dataX1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier, dataX3 got the highest score 80.333%\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(dataX, dataY, test_size=0.20, random_state=42)\n",
    "#when neighbor is 11, the score is the highest:0.741\n",
    "# for i in range(5,40):\n",
    "#     clf_KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "#     clf_KNN.fit(X2_train, Y2_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_KNN = KNeighborsClassifier(n_neighbors=11,weights = 'uniform')\n",
    "clf_KNN.fit(X2_train, Y2_train)\n",
    "#pr = clf.predict_proba(X1_test)\n",
    "print(clf_KNN.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,40):\n",
    "    clf_Knn = KNeighborsClassifier(n_neighbors=i, weights = 'uniform', algorithm = 'auto')\n",
    "    clf_KNN.fit(X2_train, Y2_train)\n",
    "    #print(clf.score(X1_test, Y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classifier   dataX5 get the highest score 95.56%\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "clf_SVM = make_pipeline(StandardScaler(), SVC(gamma='scale', kernel='rbf'))\n",
    "clf_SVM.fit(X2_train, Y2_train)\n",
    "print(clf_SVM.score(X2_test, Y2_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Process classifier \n",
    "# well, this classifier take too much time and it did not give a good score ---about 72%?\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "kernel = 1.0 * RBF(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_GPC = GaussianProcessClassifier(kernel=kernel,random_state=0,n_jobs = -1).fit(X2_train[0:700], Y2_train[0:700])\n",
    "# print(cls_GPC.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree classifier\n",
    "# The best score got 91.23% for datachannel5\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(dataX, dataY, test_size=0.20, random_state=42)\n",
    "\n",
    "clf_DT = DecisionTreeClassifier(random_state=0,criterion='entropy', splitter='best', max_depth=7,max_features=None,min_samples_split=15,min_samples_leaf=5, max_leaf_nodes=75)\n",
    "clf_DT.fit(X2_train, Y2_train)\n",
    "print(clf_DT.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,50):\n",
    "    clf_DT = DecisionTreeClassifier(random_state=0,criterion='entropy', splitter='best', max_depth=7,min_samples_split=15,min_samples_leaf=5,max_leaf_nodes=75, min_impurity_decrease=i)\n",
    "    clf_DT.fit(X2_train, Y2_train)\n",
    "#     print(clf_DT.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "#The best score is 83.11%\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(dataX, dataY, test_size=0.20, random_state=42)\n",
    "clf_RF = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_RF.fit(X2_train, Y2_train)\n",
    "print(clf_RF.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nueral Network model: Multilayer perceptron\n",
    "#best score for NN => 79.6%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(dataX, dataY, test_size=0.20, random_state=42)\n",
    "clf_NN = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(10, 2), random_state=1, activation='tanh')\n",
    "clf_NN.fit(X2_train, Y2_train)\n",
    "print(clf_NN.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### for i in range(3,20):\n",
    "    clf_NN = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(20, 2), random_state=1, activation='tanh')\n",
    "    clf_NN.fit(X2_train, Y2_train)\n",
    "    print(clf_NN.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost Classifier \n",
    "#best score 92.6\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_AB = AdaBoostClassifier(n_estimators=100, random_state=0, learning_rate=1, algorithm='SAMME.R')\n",
    "clf_AB.fit(X2_train, Y2_train)\n",
    "print(clf_AB.score(X2_test, Y2_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "# best score 68.5%\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_gnb = GaussianNB(var_smoothing = 1e-9)\n",
    "clf_gnb.fit(X2_train, Y2_train)\n",
    "print(clf_gnb.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "clf_QDA = QDA()\n",
    "clf_QDA.fit(X2_train, Y2_train)\n",
    "print(clf_QDA.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "# eclf = VotingClassifier(estimators=[ ('SVM', clf_SVM), ('DecisionTree', clf_DT), ('RandomForest', clf_RF), \n",
    "#                                    ('AdaBoost', clf_AB), ('QDA', clf_QDA)], \n",
    "#                                     voting='soft', weights=[95.5, 91.2, 83.1,92.6,84.8])\n",
    "# eclf.fit(X2_train, Y2_train)\n",
    "# print(eclf.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this voting clf: best score is 95.8\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[ ('SVM', clf_SVM), ('DecisionTree', clf_DT), ('RandomForest', clf_RF), \n",
    "                                   ('AdaBoost', clf_AB), ('QDA', clf_QDA)], \n",
    "                                    voting='hard')\n",
    "eclf.fit(X2_train, Y2_train)\n",
    "print(eclf.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this one the best score is 96.67%\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[ ('SVM', clf_SVM), ('DecisionTree', clf_DT), \n",
    "                                   ('AdaBoost', clf_AB)], \n",
    "                                    voting='hard')\n",
    "eclf.fit(X2_train, Y2_train)\n",
    "print(eclf.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
